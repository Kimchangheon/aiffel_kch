{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"D_흐린 사진을 선명하게(Super Resolution).ipynb","provenance":[],"authorship_tag":"ABX9TyMnU1ev6Zw45/nYmy1hxLfQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6obLNZh4WU_7"},"source":["Super Resolution 결과가 얼마나 좋은지 많은 연구들에서 사용되는 정량적인 평가 척도가 몇 가지 있습니다. 이번에는 이러한 척도에 대해 간략하게 알아보고 이를 활용해 앞서 진행한 SRCNN과 SRGAN 모델 각각이 만들어낸 고해상도 이미지를 비교해 봅시다.\n","\n","\n","### PSNR과 SSIM\n","\n","---\n","\n","**PSNR**(Peak Signal-to-Noise Ratio)은 영상 내 신호가 가질 수 있는 최대 신호에 대한 잡음(noise)의 비율을 나타냅니다. 일반적으로 영상을 압축했을 때 화질이 얼마나 손실되었는지 평가하는 목적으로 사용됩니다. 데시벨(db) 단위를 사용하며, PSNR 수치가 높을수록 원본 영상에 비해 손실이 적다는 의미입니다 (값이 높을수록 좋습니다).\n","\n","**SSIM**(Structural Similarity Index Map)은 영상의 구조 정보를 고려하여 얼마나 구조 정보를 변화시키지 않았는지를 계산합니다. 특정 영상에 대한 SSIM값이 높을수록 원본 영상의 품질에 가깝다는 의미입니다 (마찬가지로 값이 높을수록 좋습니다).\n","\n","이번 학습에서는 위와 같은 정량적 평가 척도에 대해 자세히 다루지는 않습니다. PSNR과 SSIM 결과가 높을수록 비교하려는 영상이 원본 영상 품질에 가깝다는 사실만 알고 넘어가셔도 되며, 이에 대해 자세히 이해하고자 하신다면 아래 참고 자료를 읽어 보시길 바랍니다.  \n","\n","* [참고 자료: 최대신호대잡음비(PSNR)와 이미지 품질](https://bskyvision.com/392)  \n","* [참고 자료: 2D 이미지 품질 평가에 구조변화를 반영하는 SSIM과 그의 변형들](https://bskyvision.com/396)\n","\n","\n","PSNR과 SSIM은 `scikit-image` 라이브러리를 이용해 쉽게 계산할 수 있습니다. 아래 코드를 따라서 간단하게 실험해 봅시다. 이전에 보았던 고양이를 다시 데려오겠습니다🐱"]},{"cell_type":"code","metadata":{"id":"_IaCfxfDWV1v"},"source":["from skimage import data\n","import matplotlib.pyplot as plt\n","\n","hr_cat = data.chelsea() # skimage에서 제공하는 예제 이미지를 불러옵니다.\n","hr_shape = hr_cat.shape[:2]\n","\n","print(hr_cat.shape) # 이미지의 크기를 출력합니다.\n","\n","plt.figure(figsize=(8,5))\n","plt.imshow(hr_cat)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6Zo8OOyxZNvA"},"source":["동일한 이미지로 PSNR과 SSIM을 계산해 보겠습니다. 아래 코드와 같이 `peak_signal_noise_ratio` , `structural_similarity` 두 메서드를 이용하면 쉽게 계산할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"JUy3unW6ZM2b"},"source":["from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n","\n","print(\"**동일 이미지 비교**\")\n","print(\"PSNR :\", peak_signal_noise_ratio(hr_cat, hr_cat))\n","print(\"SSIM :\", structural_similarity(hr_cat, hr_cat, multichannel=True))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3g29G_CsZaXy"},"source":["PSNR과 SSIM 모두 높은 값을 가질수록 원본 이미지와 가깝다는 것을 의미하며, 동일한 이미지를 비교했기 때문에 두 결과는 각각 가질 수 있는 최댓값을 가집니다. PSNR은 상한값이 없고, SSIM은 0~1 사이의 값을 가지기 때문에 각각 inf와 1이 계산됩니다.  \n","\n","\n","이번에는 아래 코드를 이용해 고양이의 가로 세로 픽셀 수를 각각 1/2, 1/4, 1/8로 줄이고, bicubic interpolation을 이용해 원래 크기로 복원해 보겠습니다. 각각 처리된 이미지에 대해 원본 이미지와의 PSNR과 SSIM을 계산하고 그 결과를 제목에 표시해 보겠습니다."]},{"cell_type":"code","metadata":{"id":"YxH0o_y6ZbcQ"},"source":["import cv2\n","\n","# 이미지를 특정 크기로 줄이고 다시 늘리는 과정을 함수로 정의합니다.\n","def interpolation_xn(image, n):\n","    downsample = cv2.resize(\n","        image,\n","        dsize=(hr_shape[1]//n, hr_shape[0]//n)\n","    )\n","    upsample = cv2.resize(\n","        downsample,\n","        dsize=(hr_shape[1], hr_shape[0]),\n","        interpolation=cv2.INTER_CUBIC\n","    )\n","    return upsample\n","\n","lr2_cat = interpolation_xn(hr_cat, 2) # 1/2로 줄이고 다시 복원\n","lr4_cat = interpolation_xn(hr_cat, 4) # 1/4로 줄이고 다시 복원\n","lr8_cat = interpolation_xn(hr_cat, 8) # 1/8로 줄이고 다시 복원\n","\n","images = [hr_cat, lr2_cat, lr4_cat, lr8_cat]\n","titles = [\"HR\", \"x2\", \"x4\", \"x8\"]\n","\n","# 각 이미지에 대해 PSNR을 계산하고 반올림합니다.\n","psnr = [round(peak_signal_noise_ratio(hr_cat, i), 3) for i in images]\n","# 각 이미지에 대해 SSIM을 계산하고 반올림합니다.\n","ssim = [round(structural_similarity(hr_cat, i, multichannel=True), 3) for i in images]\n","\n","# 이미지 제목에 PSNR과 SSIM을 포함하여 시각화 합니다. \n","plt.figure(figsize=(16,10))\n","for i in range(4):\n","    plt.subplot(2,2,i+1)\n","    plt.imshow(images[i])\n","    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"glidwUA1ZmkN"},"source":["각 이미지의 제목에 PSNR과 SSIM이 순서대로 나타났습니다. 해상도를 줄일수록 그 이미지를 원래 크기로 interploation 했을 때, 각각의 계산 결과가 눈에 띄게 감소하는 것을 알 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"fG6-1EWgZwR0"},"source":["## E-22-11. SRCNN 및 SRGAN 결과 비교하기"]},{"cell_type":"markdown","metadata":{"id":"KE7r736WZzf7"},"source":["이번에는 앞서 실험했던 SRCNN과 SRGAN의 결과를 먼저 시각적으로만 비교해 보겠습니다. 이전에 불러온 DIV2K 데이터셋 내에서 학습에 사용하지 않은 검증용 데이터셋을 이용하며, 몇 개 이미지만 뽑아서 Super Resolution을 진행한 후 특정 부분을 잘라내어 확대해봅시다."]},{"cell_type":"code","metadata":{"id":"GCSpAv1zZ0hr"},"source":["for i, (lr, hr) in enumerate(valid):\n","    if i == 12: break # 12번째 이미지를 불러옵니다.\n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","\n","# bicubic interpolation\n","bicubic_img = cv2.resize(\n","    lr_img, \n","    (hr.shape[1], hr.shape[0]), \n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","# 전체 이미지를 시각화합니다.\n","plt.figure(figsize=(20,15))\n","plt.subplot(311); plt.imshow(hr_img)\n","\n","# SRCNN을 이용해 고해상도로 변환합니다.\n","srcnn_img = apply_srcnn(bicubic_img)\n","\n","# SRGAN을 이용해 고해상도로 변환합니다.\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","left_top = (700, 1090) # 잘라낼 부분의 왼쪽 상단 좌표를 지정합니다.\n","\n","# bicubic, SRCNN, SRGAN 을 적용한 이미지와 원래의 고해상도 이미지를 시각화합니다.\n","plt.figure(figsize=(20,20))\n","for i, pind in enumerate([321, 322, 323, 324]):\n","    plt.subplot(pind)\n","    plt.imshow(crop(images[i], left_top, 200, 350))\n","    plt.title(titles[i], fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6vEWGifJZzdS"},"source":["자동차의 앞부분을 잘라내어 확대했습니다. HR이라는 제목을 가진 고해상도 이미지와 비교할 때, Bicubic과 SRCNN은 많이 흐릿하지만 SRGAN의 결과는 매우 비슷하네요😃  \n","\n","\n","아래 코드를 실행하면서 몇 가지 이미지에 대해 동일한 과정으로 비교해봅시다."]},{"cell_type":"code","metadata":{"id":"t3QSvERkaX3t"},"source":["for i, (lr, hr) in enumerate(valid):\n","    if i == 15: break\n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img, \n","    (hr.shape[1], hr.shape[0]), \n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","plt.figure(figsize=(20,15))\n","plt.subplot(311); plt.imshow(hr_img)\n","\n","srcnn_img = apply_srcnn(bicubic_img)\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","left_top = (600, 1500)\n","\n","plt.figure(figsize=(20,20))\n","for i, pind in enumerate([321, 322, 323, 324]):\n","    plt.subplot(pind)\n","    plt.imshow(crop(images[i], left_top, 200, 350))\n","    plt.title(titles[i], fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ivl4_ovZaX6X"},"source":["for i, (lr, hr) in enumerate(valid):\n","    if i == 8: break\n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img, \n","    (hr.shape[1], hr.shape[0]), \n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","plt.figure(figsize=(20,15))\n","plt.subplot(311); plt.imshow(hr_img)\n","\n","srcnn_img = apply_srcnn(bicubic_img)\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","left_top = (900, 1500)\n","\n","plt.figure(figsize=(20,20))\n","for i, pind in enumerate([321, 322, 323, 324]):\n","    plt.subplot(pind)\n","    plt.imshow(crop(images[i], left_top, 200, 350))\n","    plt.title(titles[i], fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u3UrDWRaaX9G"},"source":["for i, (lr, hr) in enumerate(valid):\n","    if i == 24: break\n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img, \n","    (hr.shape[1], hr.shape[0]), \n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","plt.figure(figsize=(20,15))\n","plt.subplot(311); plt.imshow(hr_img)\n","\n","srcnn_img = apply_srcnn(bicubic_img)\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","left_top = (700, 1300)\n","\n","plt.figure(figsize=(20,20))\n","for i, pind in enumerate([321, 322, 323, 324]):\n","    plt.subplot(pind)\n","    plt.imshow(crop(images[i], left_top, 200, 350))\n","    plt.title(titles[i], fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mnEFnIi-Zza3"},"source":["아래 코드에서는 여러분이 직접 이미지를 고르고, 잘라내어 확대할 부분을 지정하여 실행해 봅시다. 코드 내 **`##TODO##`** 라고 쓰여진 두 부분을 입력하면 됩니다."]},{"cell_type":"code","metadata":{"id":"TMj4z6U2avJM"},"source":["for i, (lr, hr) in enumerate(valid):\n","    # 불러올 이미지의 인덱스를 지정합니다.\n","    # 위에서 시각화 했던 8, 12, 15, 24 번을 제외한 다른 숫자를 넣어봅시다 \n","    if i == ##TODO## : \n","        break          \n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img, \n","    (hr.shape[1], hr.shape[0]), \n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","plt.figure(figsize=(20,15))\n","plt.subplot(311); plt.imshow(hr_img)\n","\n","srcnn_img = apply_srcnn(bicubic_img)\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","# 잘라낼 부분의 왼쪽 상단 좌표를 지정합니다.\n","left_top = ##TODO## \n","\n","plt.figure(figsize=(20,20)) # 이미지 크기를 조절할 수 있습니다.\n","for i, pind in enumerate([321, 322, 323, 324]):\n","    plt.subplot(pind)\n","    # crop 함수 내의 세번째 네번째 인자를 수정해 이미지 크기를 조절합니다.\n","    plt.imshow(crop(images[i], left_top, 200, 350))\n","    plt.title(titles[i], fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D_L5qpYtawxT"},"source":["이번에는 각 Super Resolution 결과와 원래 고해상도 이미지 사이의 PSNR, SSIM을 계산해 보겠습니다. 이전과 마찬가지로 아래 코드를 이용해 각 이미지의 제목에 평가 결과를 함께 표시하도록 합니다."]},{"cell_type":"code","metadata":{"id":"5vUZ2Dmza10b"},"source":["for i, (lr, hr) in enumerate(valid):\n","    if i == 24: break\n","    \n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img,\n","    (hr.shape[1], hr.shape[0]),\n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","srcnn_img = apply_srcnn(bicubic_img)\n","srgan_img = apply_srgan(lr_img)\n","\n","images = [bicubic_img, srcnn_img, srgan_img, hr_img]\n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","# 각 이미지에 대해 PSNR을 계산하고 반올림합니다.\n","psnr = [round(peak_signal_noise_ratio(hr_img, i), 3) for i in images]\n","# 각 이미지에 대해 SSIM을 계산하고 반올림합니다.\n","ssim = [round(structural_similarity(hr_img, i, multichannel=True), 3) for i in images]\n","\n","# 이미지 제목에 PSNR과 SSIM을 포함하여 시각화 합니다. \n","plt.figure(figsize=(18,13))\n","for i in range(4):\n","    plt.subplot(2,2,i+1)\n","    plt.imshow(images[i])\n","    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Sp0hfPVZzYq"},"source":["어떻게 된 일인지 시각적으로 가장 고해상도 이미지에 가까웠던 SRGAN의 결과가 다른 방법들에 비해 낮은 PSNR과 SSIM 결과를 가집니다. 아래에서 이 이미지에 대해 특정 부분을 잘라내고, 잘라낸 이미지로 PSNR, SSIM을 계산해 봅시다.  \n","\n","건물의 창문 부분을 잘라 자세히 보겠습니다."]},{"cell_type":"code","metadata":{"id":"8ImuICqba-F3"},"source":["left_top = (620, 570)\n","crop_images = [crop(i, left_top, 150, 250) for i in images]\n","\n","psnr = [round(peak_signal_noise_ratio(crop_images[-1], i), 3) for i in crop_images]\n","ssim = [round(structural_similarity(crop_images[-1], i, multichannel=True), 3) for i in crop_images]\n","\n","plt.figure(figsize=(18,10))\n","for i in range(4):\n","    plt.subplot(2,2,i+1)\n","    plt.imshow(crop_images[i])\n","    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lAhZ2G_IZzWN"},"source":["SRCNN 결과의 경우 약간 선명해졌지만 전체적으로 여전히 고해상도 영상에 비해 흐릿합니다. SRCNN의 학습에 `Mean Squared Error`를 사용했기 때문에, 생성해야 할 픽셀 값들을 고해상도 이미지와 비교해 단순히 평균적으로 잘 맞추는 방향으로 예측했기 때문입니다. 이러한 문제는 SRCNN 뿐만 아니라 MSE만을 사용해 학습하는 대부분의 신경망에서 발생하는 현상이기도 합니다.  \n","\n","\n","SRGAN 결과의 경우 매우 선명하게 이상함을 확인할 수 있습니다. 이는 Generator가 고해상도 이미지를 생성하는 과정에서 Discriminator를 속이기 위해 이미지를 진짜 같이 선명하게 만들도록 학습 되었기 때문입니다. 추가로 앞서 설명했듯이 VGG구조를 이용한 `content loss`를 통해 학습한 것 또한 사실적인 이미지를 형성하는데 크게 기여했다고 합니다. 다만, 입력되었던 저해상도 이미지가 매우 제한된 정보를 가지고 있기에 고해상도 이미지와 세부적으로 동일한 모양으로 선명하진 않은 것이죠.  \n","\n","\n","아래 코드에서는 여러분이 직접 이미지를 골라 잘라내고, 그 영역에 대해서만 PSNR과 SSIM을 계산하여 제목에 표시해 봅시다. 데이터 및 잘라낸 위치에 따라 위와 반대로 SRGAN의 정량적 평가가 더 좋게 나오는 부분이 있을 것입니다. 코드 내 `##TODO##` 라고 쓰여진 부분을 입력하면 됩니다."]},{"cell_type":"code","metadata":{"id":"RspdBHYobHKW"},"source":["for i, (lr, hr) in enumerate(valid):\n","    # 불러올 이미지의 인덱스를 지정합니다.\n","    # 위에서 시각화 했던 8, 12, 15, 24 번을 제외한 다른 숫자를 넣어봅시다 \n","    if i == ##TODO## : \n","        break          \n","\n","lr_img, hr_img = np.array(lr), np.array(hr)\n","bicubic_img = cv2.resize(\n","    lr_img,\n","    (hr.shape[1], hr.shape[0]),\n","    interpolation=cv2.INTER_CUBIC\n",")\n","\n","# 확대할 부분의 왼쪽 상단 좌표를 지정합니다.\n","left_top = ##TODO## \n","\n","# crop 함수 내의 세번째 네번째 인자를 수정해 이미지 크기를 조절합니다.\n","crop_images = [crop(i, left_top, 150, 250) for i in images] \n","titles = [\"Bicubic\", \"SRCNN\", \"SRGAN\", \"HR\"]\n","\n","psnr = [round(peak_signal_noise_ratio(crop_images[-1], i), 3) for i in crop_images]\n","ssim = [round(structural_similarity(crop_images[-1], i, multichannel=True), 3) for i in crop_images]\n","\n","plt.figure(figsize=(18,10)) # 이미지 크기를 조절할 수 있습니다.\n","for i in range(4):\n","    plt.subplot(2,2,i+1)\n","    plt.imshow(crop_images[i])\n","    plt.title(titles[i] + f\" [{psnr[i]}/{ssim[i]}]\", fontsize=30)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iocndxDSZzTe"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"w2K_uSrgZzQ8"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"qDPJ0JBoZzOS"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"TPtqgSpbZzMG"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"7XUR5MAAZzJe"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Y_gMHiC5Zy6K"},"source":[""]},{"cell_type":"code","metadata":{"id":"0qRy0naXZm3t"},"source":[""],"execution_count":null,"outputs":[]}]}