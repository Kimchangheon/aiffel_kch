{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"따라하자 딥러닝  19. 난 스케치를 할 테니 너는 채색을 하거라 (1).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPZBPB8GYrYuvSDlXryDQRV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"temscw9D3QRa"},"source":["!mkdir -p ~/aiffel/conditional_generation/data\n","!ln -s ~/data/* ~/aiffel/conditional_generation/data\n","# 압축 해제 시 3분 정도 소요됩니다.\n","!cd ~/aiffel/conditional_generation/data && unzip sketch2pokemon.zip\n","\n","import os\n","\n","data_path = os.getenv('HOME')+'/aiffel/conditional_generation/data/pokemon_pix2pix_dataset/train/'\n","print(\"number of train examples :\", len(os.listdir(data_path)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eh9b6Agg4Lzi"},"source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20,15))\n","for i in range(1, 7):\n","    f = data_path + os.listdir(data_path)[np.random.randint(800)]\n","    img = cv2.imread(f, cv2.IMREAD_COLOR)\n","    plt.subplot(3,2,i)\n","    plt.imshow(img)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TBt9iwDg4L2K"},"source":["f = data_path + os.listdir(data_path)[0]\n","img = cv2.imread(f, cv2.IMREAD_COLOR)\n","print(img.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lTn-J3I44L4w"},"source":["import tensorflow as tf\n","\n","def normalize(x):\n","    x = tf.cast(x, tf.float32)\n","    return (x/127.5) - 1\n","\n","def denormalize(x):\n","    x = (x+1)*127.5\n","    x = x.numpy()\n","    return x.astype(np.uint8)\n","\n","def load_img(img_path):\n","    img = tf.io.read_file(img_path)\n","    img = tf.image.decode_image(img, 3)\n","    \n","    w = tf.shape(img)[1] // 2\n","    sketch = img[:, :w, :] \n","    sketch = tf.cast(sketch, tf.float32)\n","    colored = img[:, w:, :] \n","    colored = tf.cast(colored, tf.float32)\n","    return normalize(sketch), normalize(colored)\n","\n","f = data_path + os.listdir(data_path)[1]\n","sketch, colored = load_img(f)\n","\n","plt.figure(figsize=(10,7))\n","plt.subplot(1,2,1); plt.imshow(denormalize(sketch))\n","plt.subplot(1,2,2); plt.imshow(denormalize(colored))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FRnclh4p4L7l"},"source":["from tensorflow import image\n","from tensorflow.keras.preprocessing.image import random_rotation\n","\n","@tf.function() # 빠른 텐서플로 연산을 위해 @tf.function()을 사용합니다. \n","def apply_augmentation(sketch, colored):\n","    stacked = tf.concat([sketch, colored], axis=-1)\n","    \n","    _pad = tf.constant([[30,30],[30,30],[0,0]])\n","    if tf.random.uniform(()) < .5:\n","        padded = tf.pad(stacked, _pad, \"REFLECT\")\n","    else:\n","        padded = tf.pad(stacked, _pad, \"CONSTANT\", constant_values=1.)\n","\n","    out = image.random_crop(padded, size=[256, 256, 6])\n","    \n","    out = image.random_flip_left_right(out)\n","    out = image.random_flip_up_down(out)\n","    \n","    if tf.random.uniform(()) < .5:\n","        degree = tf.random.uniform([], minval=1, maxval=4, dtype=tf.int32)\n","        out = image.rot90(out, k=degree)\n","    \n","    return out[...,:3], out[...,3:]   \n","\n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vf8VSCDd4RQk"},"source":["plt.figure(figsize=(15,13))\n","img_n = 1\n","for i in range(1, 13, 2):\n","    augmented_sketch, augmented_colored = apply_augmentation(sketch, colored)\n","    \n","    plt.subplot(3,4,i)\n","    plt.imshow(denormalize(augmented_sketch)); plt.title(f\"Image {img_n}\")\n","    plt.subplot(3,4,i+1); \n","    plt.imshow(denormalize(augmented_colored)); plt.title(f\"Image {img_n}\")\n","    img_n += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jn2riUl24RTK"},"source":["from tensorflow import data\n","\n","def get_train(img_path):\n","    sketch, colored = load_img(img_path)\n","    sketch, colored = apply_augmentation(sketch, colored)\n","    return sketch, colored\n","\n","train_images = data.Dataset.list_files(data_path + \"*.jpg\")\n","train_images = train_images.map(get_train).shuffle(100).batch(4)\n","\n","sample = train_images.take(1)\n","sample = list(sample.as_numpy_iterator())\n","sketch, colored = (sample[0][0]+1)*127.5, (sample[0][1]+1)*127.5\n","\n","plt.figure(figsize=(10,5))\n","plt.subplot(1,2,1); plt.imshow(sketch[0].astype(np.uint8))\n","plt.subplot(1,2,2); plt.imshow(colored[0].astype(np.uint8))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U1byx6DH4RWS"},"source":["from tensorflow.keras import layers, Input, Model\n","\n","class EncodeBlock(layers.Layer):\n","    def __init__(self, n_filters, use_bn=True):\n","        super(EncodeBlock, self).__init__()\n","        self.use_bn = use_bn       \n","        self.conv = layers.Conv2D(n_filters, 4, 2, \"same\", use_bias=False)\n","        self.batchnorm = layers.BatchNormalization()\n","        self.lrelu= layers.LeakyReLU(0.2)\n","\n","    def call(self, x):\n","        x = self.conv(x)\n","        if self.use_bn:\n","            x = self.batchnorm(x)\n","        return self.lrelu(x)\n","\n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"MtXd4swQ4hJx","executionInfo":{"status":"error","timestamp":1627018918455,"user_tz":-540,"elapsed":423,"user":{"displayName":"화학물질데이터과학연구센터","photoUrl":"","userId":"10367021151084952000"}},"outputId":"872dc584-6609-4cee-d078-59c107a8d0c8"},"source":["class Encoder(layers.Layer):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","        filters = [64,128,256,512,512,512,512,512]\n","        \n","        self.blocks = []\n","        for i, f in enumerate(filters):\n","            if i == 0:\n","                self.blocks.append(EncodeBlock(f, use_bn=False))\n","            else:\n","                self.blocks.append(EncodeBlock(f))\n","    \n","    def call(self, x):\n","        for block in self.blocks:\n","            x = block(x)\n","        return x\n","    \n","    def get_summary(self, input_shape=(256,256,3)):\n","        inputs = Input(input_shape)\n","        return Model(inputs, self.call(inputs)).summary()\n","\n","print(\"✅\")"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-a74e862a0816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'layers' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"sS6gC9Su4hMd","executionInfo":{"status":"error","timestamp":1627018910864,"user_tz":-540,"elapsed":10,"user":{"displayName":"화학물질데이터과학연구센터","photoUrl":"","userId":"10367021151084952000"}},"outputId":"47352fbb-e721-4ead-b505-3a5f689dee2e"},"source":["Encoder().get_summary()"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d69d29ec3e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Encoder' is not defined"]}]},{"cell_type":"code","metadata":{"id":"F37JoUrD4hPC"},"source":["class DecodeBlock(layers.Layer):\n","    def __init__(self, f, dropout=True):\n","        super(DecodeBlock, self).__init__()\n","        self.dropout = dropout\n","        self.Transconv = layers.Conv2DTranspose(f, 4, 2, \"same\", use_bias=False)\n","        self.batchnorm = layers.BatchNormalization()\n","        self.relu = layers.ReLU()\n","        \n","    def call(self, x):\n","        x = self.Transconv(x)\n","        x = self.batchnorm(x)\n","        if self.dropout:\n","            x = layers.Dropout(.5)(x)\n","        return self.relu(x)\n","\n","    \n","class Decoder(layers.Layer):\n","    def __init__(self):\n","        super(Decoder, self).__init__()\n","        filters = [512,512,512,512,256,128,64]\n","        \n","        self.blocks = []\n","        for i, f in enumerate(filters):\n","            if i < 3:\n","                self.blocks.append(DecodeBlock(f))\n","            else:\n","                self.blocks.append(DecodeBlock(f, dropout=False))\n","                \n","        self.blocks.append(layers.Conv2DTranspose(3, 4, 2, \"same\", use_bias=False))\n","        \n","    def call(self, x):\n","        for block in self.blocks:\n","            x = block(x)\n","        return x\n","            \n","    def get_summary(self, input_shape=(1,1,256)):\n","        inputs = Input(input_shape)\n","        return Model(inputs, self.call(inputs)).summary()\n","        \n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"7uHPa42O4qCI","executionInfo":{"status":"error","timestamp":1627018933844,"user_tz":-540,"elapsed":301,"user":{"displayName":"화학물질데이터과학연구센터","photoUrl":"","userId":"10367021151084952000"}},"outputId":"35a2f7f4-6380-4ae8-9b35-f1a02c7ba024"},"source":["Decoder().get_summary()"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ccdc612072dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'Decoder' is not defined"]}]},{"cell_type":"code","metadata":{"id":"Ta8Itndf4rN2"},"source":["class EncoderDecoderGenerator(Model):\n","    def __init__(self):\n","        super(EncoderDecoderGenerator, self).__init__()\n","        self.encoder = Encoder()\n","        self.decoder = Decoder()\n","    \n","    def call(self, x):\n","        x = self.encoder(x)\n","        x = self.decoder(x)\n","        return x\n","   \n","    def get_summary(self, input_shape=(256,256,3)):\n","        inputs = Input(input_shape)\n","        return Model(inputs, self.call(inputs)).summary()\n","        \n","\n","EncoderDecoderGenerator().get_summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sfbsxZjV4rcs"},"source":["class EncodeBlock(layers.Layer):\n","    def __init__(self, n_filters, use_bn=True):\n","        super(EncodeBlock, self).__init__()\n","        self.use_bn = use_bn       \n","        self.conv = layers.Conv2D(n_filters, 4, 2, \"same\", use_bias=False)\n","        self.batchnorm = layers.BatchNormalization()\n","        self.lrelu = layers.LeakyReLU(0.2)\n","\n","    def call(self, x):\n","        x = self.conv(x)\n","        if self.use_bn:\n","            x = self.batchnorm(x)\n","        return self.lrelu(x)\n","\n","    \n","class DecodeBlock(layers.Layer):\n","    def __init__(self, f, dropout=True):\n","        super(DecodeBlock, self).__init__()\n","        self.dropout = dropout\n","        self.Transconv = layers.Conv2DTranspose(f, 4, 2, \"same\", use_bias=False)\n","        self.batchnorm = layers.BatchNormalization()\n","        self.relu = layers.ReLU()\n","        \n","    def call(self, x):\n","        x = self.Transconv(x)\n","        x = self.batchnorm(x)\n","        if self.dropout:\n","            x = layers.Dropout(.5)(x)\n","        return self.relu(x)\n","    \n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E3wQgApa4rfY"},"source":["class UNetGenerator(Model):\n","    def __init__(self):\n","        super(UNetGenerator, self).__init__()\n","        encode_filters = [64,128,256,512,512,512,512,512]\n","        decode_filters = [512,512,512,512,256,128,64]\n","        \n","        self.encode_blocks = []\n","        for i, f in enumerate(encode_filters):\n","            if i == 0:\n","                self.encode_blocks.append(EncodeBlock(f, use_bn=False))\n","            else:\n","                self.encode_blocks.append(EncodeBlock(f))\n","        \n","        self.decode_blocks = []\n","        for i, f in enumerate(decode_filters):\n","            if i < 3:\n","                self.decode_blocks.append(DecodeBlock(f))\n","            else:\n","                self.decode_blocks.append(DecodeBlock(f, dropout=False))\n","        \n","        self.last_conv = layers.Conv2DTranspose(3, 4, 2, \"same\", use_bias=False)\n","    \n","    def call(self, x):\n","        features = []\n","        for block in self.encode_blocks:\n","            x = block(x)\n","            features.append(x)\n","        \n","        features = features[:-1]\n","                    \n","        for block, feat in zip(self.decode_blocks, features[::-1]):\n","            x = block(x)\n","            x = layers.Concatenate()([x, feat])\n","        \n","        x = self.last_conv(x)\n","        return x\n","                \n","    def get_summary(self, input_shape=(256,256,3)):\n","        inputs = Input(input_shape)\n","        return Model(inputs, self.call(inputs)).summary()\n","\n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LH6qxgfp4rid"},"source":["UNetGenerator().get_summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mxpEOE7I4rpK"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vb6aMPZB5QIw"},"source":["따라하자 딥러닝\n","\n","20. 난 스케치를 할 테니 너는 채색을 하거라 (2)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":237},"id":"0c9k1Opc5B5N","executionInfo":{"status":"error","timestamp":1627019101100,"user_tz":-540,"elapsed":2185,"user":{"displayName":"화학물질데이터과학연구센터","photoUrl":"","userId":"10367021151084952000"}},"outputId":"0635985e-c111-4da6-e8e9-43c162a3df1f"},"source":["class DiscBlock(layers.Layer):\n","    def __init__(self, n_filters, stride=2, custom_pad=False, use_bn=True, act=True):\n","        super(DiscBlock, self).__init__()\n","        self.custom_pad = custom_pad\n","        self.use_bn = use_bn\n","        self.act = act\n","        \n","        if custom_pad:\n","            self.padding = layers.ZeroPadding2D()\n","            self.conv = layers.Conv2D(n_filters, 4, stride, \"valid\", use_bias=False)\n","        else:\n","            self.conv = layers.Conv2D(n_filters, 4, stride, \"same\", use_bias=False)\n","        \n","        self.batchnorm = layers.BatchNormalization() if use_bn else None\n","        self.lrelu = layers.LeakyReLU(0.2) if act else None\n","        \n","    def call(self, x):\n","        if self.custom_pad:\n","            x = self.padding(x)\n","            x = self.conv(x)\n","        else:\n","            x = self.conv(x)\n","                \n","        if self.use_bn:\n","            x = self.batchnorm(x)\n","            \n","        if self.act:\n","            x = self.lrelu(x)\n","        return x \n","\n","print(\"✅\")"],"execution_count":4,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-54ccde9de860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'HOME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/aiffel/conditional_generation/data/pokemon_pix2pix_dataset/train/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"number of train examples :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/root/aiffel/conditional_generation/data/pokemon_pix2pix_dataset/train/'"]}]},{"cell_type":"code","metadata":{"id":"bP9hox5r5B75"},"source":["inputs = Input((128,128,32))\n","out = layers.ZeroPadding2D()(inputs)\n","out = layers.Conv2D(64, 4, 1, \"valid\", use_bias=False)(out)\n","out = layers.BatchNormalization()(out)\n","out = layers.LeakyReLU(0.2)(out)\n","\n","Model(inputs, out).summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3HHtxEoN5B-9"},"source":["class Discriminator(Model):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        \n","        self.block1 = layers.Concatenate()\n","        self.block2 = DiscBlock(n_filters=64, stride=2, custom_pad=False, use_bn=False, act=True)\n","        self.block3 = DiscBlock(n_filters=128, stride=2, custom_pad=False, use_bn=True, act=True)\n","        self.block4 = DiscBlock(n_filters=256, stride=2, custom_pad=False, use_bn=True, act=True)\n","        self.block5 = DiscBlock(n_filters=512, stride=1, custom_pad=True, use_bn=True, act=True)\n","        self.block6 = DiscBlock(n_filters=1, stride=1, custom_pad=True, use_bn=False, act=False)\n","        self.sigmoid = layers.Activation(\"sigmoid\")\n","        \n","        # filters = [64,128,256,512,1]\n","        # self.blocks = [layers.Concatenate()]\n","        # for i, f in enumerate(filters):\n","        #     self.blocks.append(DiscBlock(\n","        #         n_filters=f,\n","        #         strides=2 if i<3 else 1,\n","        #         custom_pad=False if i<3 else True,\n","        #         use_bn=False if i==0 and i==4 else True,\n","        #         act=True if i<4 else False\n","        #     ))\n","    \n","    def call(self, x, y):\n","        out = self.block1([x, y])\n","        out = self.block2(out)\n","        out = self.block3(out)\n","        out = self.block4(out)\n","        out = self.block5(out)\n","        out = self.block6(out)\n","        return self.sigmoid(out)\n","    \n","    def get_summary(self, x_shape=(256,256,3), y_shape=(256,256,3)):\n","        x, y = Input(x_shape), Input(y_shape) \n","        return Model((x, y), self.call(x, y)).summary()\n","    \n","print(\"✅\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KH5kgwz95kWw"},"source":["Discriminator().get_summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnHkk0Hn5kZf"},"source":["x = tf.random.normal([1,256,256,3])\n","y = tf.random.uniform([1,256,256,3])\n","\n","disc_out = Discriminator()(x, y)\n","plt.imshow(disc_out[0, ... ,0])\n","plt.colorbar()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R04n78JM5kb4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1s8AWen5ke2"},"source":[""],"execution_count":null,"outputs":[]}]}